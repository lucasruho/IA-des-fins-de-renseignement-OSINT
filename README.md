# Projet IA Ã  des fins de Renseignement

ğŸ‘¥ **Ã‰quipe projet :**  
- LOTTIAUX Adrien 
- RUHOMUTALLY Lucas  

Projet rÃ©alisÃ© dans le cadre du module *IA Ã  des fins de renseignement (OSINT)*  
Plateforme : SSPCloud (Onyxia)

*TestÃ© avec Python 3.10+*

##  Sommaire
- [1. PrÃ©sentation rapide du projet](#1-prÃ©sentation-rapide-du-projet)
- [2. Description des Ã©tapes](#2-description-des-Ã©tapes)
- [3. Tableau rÃ©capitulatif](#3-tableau-rÃ©capitulatif)
- [4. Tutoriel dâ€™utilisation](#4-tutoriel-dutilisation)
- [5. DÃ©pendances par partie](#5-dÃ©pendances-par-partie)
- [6. RÃ©sultats analytiques et visualisation](#6-rÃ©sultats-analytiques-et-visualisation)
- [7. RÃ©sumÃ©](#7-rÃ©sumÃ©)

## 1. PrÃ©sentation rapide du projet
Ce projet vise Ã  construire un corpus dâ€™articles issus du site **TASS** (agence de presse russe), puis Ã  mettre en place une chaÃ®ne dâ€™analyse OSINT complÃ¨te :  
1. **Collecte** dâ€™articles via API,  
2. **Extraction** du texte et des mÃ©tadonnÃ©es,  
3. **Analyse NER (entitÃ©s nommÃ©es)**,  
4. **Structuration sÃ©mantique via LLM (Mistral)**,  
5. **Indexation et visualisation** des rÃ©sultats dans Elasticsearch/Kibana.  

Lâ€™objectif est de **comprendre la rhÃ©torique dâ€™Ã‰tat russe** en Ã©tudiant les acteurs, lieux, thÃ¨mes et sentiments prÃ©sents dans les articles.

>Ce pipeline OSINT automatise la transformation dâ€™une source mÃ©diatique brute (TASS) en une base de donnÃ©es exploitable pour lâ€™analyse stratÃ©gique, permettant de dÃ©tecter les tendances narratives, la perception internationale de la Russie, et la polaritÃ© des discours dans le temps.


---

## 2. Description des Ã©tapes

### Objectif 1 â€” RÃ©cupÃ©rer et filtrer les articles (API TASS)
- Envoie une requÃªte POST Ã  lâ€™API TASS `categoryNewsList` pour rÃ©cupÃ©rer des articles.
- Filtre les articles selon une plage de dates dÃ©finie.
- Sauvegarde la sortie dans `data/resultat_filtre.json`.

**Sortie :** `resultat_filtre.json` â€” liste dâ€™articles filtrÃ©s avec leurs mÃ©tadonnÃ©es de base.

---

### Objectif 2 â€” Extraire le contenu complet des articles
- Lit le fichier `resultat_filtre.json`.
- TÃ©lÃ©charge le contenu HTML de chaque article.
- Extrait le **texte principal** et les **tags** via *BeautifulSoup*.
- Conserve les mÃ©tadonnÃ©es originales et sauvegarde dans `data/articles_complets.json`.

**Sortie :** `articles_complets.json` â€” texte complet + tags pour chaque article.

---

### Objectif 3 â€” Reconnaissance dâ€™entitÃ©s nommÃ©es (NER)
- Utilise le modÃ¨le **spaCy** `en_core_web_trf` pour dÃ©tecter les entitÃ©s : `PERSON`, `ORG`, `GPE`, `PRODUCT`, `EVENT`.
- Nettoie et dÃ©duplique les entitÃ©s dÃ©tectÃ©es.
- Produit un fichier `data/articles_avec_ner_clean.json`.



**Sortie :** `articles_avec_ner_clean.json` â€” articles enrichis avec les entitÃ©s NER nettoyÃ©es.

---

### Objectif 3BIS â€” Structuration sÃ©mantique via LLM (Mistral)
- Utilise lâ€™API **Mistral** via le SDK `mistralai`.
- NÃ©cessite une **clÃ© API Mistral** Ã  placer dans un fichier `.env` : `cle_API=VOTRE_CLE_MISTRAL`
- Le LLM renvoie une **analyse structurÃ©e** :
  - `topics`  
  - `overall_sentiment`  
  - `sentiment_by_country` (avec codes ISO2)  
  - `actors_mentioned`  
  - `article_type`  
  - `id`

#### **Note importante :**
Lâ€™analyse a Ã©tÃ© rÃ©alisÃ©e sur 100 articles issus du jeu de donnÃ©es fourni par Baptiste HUVELLE afin dâ€™accÃ©lÃ©rer le traitement et de limiter la consommation de tokens lors des appels Ã  lâ€™API Mistral.

**Sortie :** `data/resultat_llm_mistral_final.json` â€” analyse sÃ©mantique enrichie de chaque article.

---


### Objectif 4 â€” Indexation et visualisation (Elasticsearch & Kibana)
- Nous avons utilisÃ© le fichier JSON complet fourni par le professeur, contenant 21 742 articles issus de tass.com, afin de rÃ©aliser des dashboards complets.
- Le script `Objectif4_elastic.py` permet dâ€™adapter et dâ€™envoyer la base de donnÃ©es complÃ¨te dans Elasticsearch.
- Lâ€™index contient :
  - les `tags`, `ner.*` (PERSON, ORG, GPE, etc.),
  - les `structured.*` (topics, sentiments, acteurs, etc.).

Pour crÃ©er un dashboard du sentiment global par pays, nous avons dâ€™abord restructurÃ© les donnÃ©es Ã  lâ€™aide du script `convertir_pays.py`.

Ce script gÃ©nÃ¨re le fichier `articles_pays_21k.json` au format suivant :
```json
[
  { "id": 2035207, "date": 1761470423, "country": "RU", "sentiment": 0.5 },
  { "id": 2035199, "date": 1761467797, "country": "RU", "sentiment": 0.1 },
  { "id": 2035199, "date": 1761467797, "country": "UA", "sentiment": -0.7 }
]
```

**Sortie :** un **index Elasticsearch** prÃªt Ã  lâ€™emploi pour dashboards Kibana.

---

## 3. Tableau rÃ©capitulatif

| Ã‰tape | Script                         | EntrÃ©e                                               | Sortie JSON                       | Description                            |
| :---: | :----------------------------- | :--------------------------------------------------- | :-------------------------------- | :------------------------------------- |
|   1   | `Objectif1_trier_articles.py`  | tass.com                                             | `resultat_filtre.json`            | RÃ©cupÃ¨re et filtre les articles        |
|   2   | `Objectif2_contenu_article.py` | `resultat_filtre.json`                               | `articles_complets.json`          | Extrait texte complet et tags          |
|   3   | `Objectif3_NER.py`             | `articles_complets.json`                             | `articles_avec_ner_clean.json`    | DÃ©tecte et nettoie les entitÃ©s nommÃ©es |
|  3BIS | `Objectif3BIS_LLM.py`          | 100 articles `resultat_bapt_100.json`                | `resultat_llm_mistral_final.json` | Analyse sÃ©mantique via LLM (Mistral)   |
|   4   | `Objectif4_elastic.py`         | JSON du professeur (21 742 articles) `stage4_v3.json`| Index Elasticsearch               | Envoie la base complÃ¨te vers Elastic   |


---

## 4. Tutoriel dâ€™utilisation

### Ã‰tapes 1 Ã  3 (avec 3BIS) â€” via **Onyxia SSPCloud Datalab**

1. **Lancer** un service **VSCode-Python** sur Onyxia (SSPCloud).  
2. **Cloner** le dÃ©pÃ´t du projet.  
3. **Installer les bibliothÃ¨ques nÃ©cessaires :**
 ```bash
 pip install requests beautifulsoup4 spacy python-dotenv mistralai elasticsearch
 python -m spacy download en_core_web_trf
 ```
4. ExÃ©cuter les scripts dans lâ€™ordre :

```bash
python Objectif1_trier_articles.py
python Objectif2_contenu_article.py
python Objectif3_NER.py
```

5. Configurer la clÃ© Mistral (Objectif 3BIS) :
- CrÃ©ez un fichier .env : `cle_API=VOTRE_CLE_MISTRAL`
- Puis lancer :
  ```bash
   python Objectif3BIS_LLM.py
  ```

### Ã‰tape 4 â€” via Docker Compose en local
Cette Ã©tape te permet de dÃ©marrer un **cluster Elasticsearch multi-nÅ“uds avec Kibana** Ã  lâ€™aide de **Docker Compose**, comme dÃ©crit dans la documentation officielle Elastic.

> âš ï¸ Attention : ne pas versionner le fichier .env contenant la clÃ© API Mistral.

#### 1. PrÃ©paration
1. Installer **Docker** et **Docker Compose**.  

2. CrÃ©er un **nouveau dossier** de projet vide (ex: `elastic-cluster`).

3. TÃ©lÃ©charger les deux fichiers de configuration officiels :
   - [`docker-compose.yml`](https://github.com/elastic/elasticsearch/blob/master/docs/reference/setup/install/docker/docker-compose.yml)
   - [`.env`](https://github.com/elastic/elasticsearch/blob/master/docs/reference/setup/install/docker/.env)

   Les placer dans ton dossier `elastic-cluster/`.

---

#### 2. Configuration du fichier `.env`

Ouvrir le fichier `.env` et **modifier les variables suivantes** :

```bash
# Mot de passe pour l'utilisateur 'elastic' (min. 6 caractÃ¨res alphanumÃ©riques)
ELASTIC_PASSWORD=changeme

# Mot de passe pour l'utilisateur 'kibana_system'
KIBANA_PASSWORD=changeme

# Version de la stack Elastic (Ã  ajuster si besoin)
STACK_VERSION=9.2.0

# Port HTTP exposÃ© (ne pas exposer publiquement)
ES_PORT=127.0.0.1:9200
```
#### 3. DÃ©marrer le cluster :
Depuis le dossier du projet :
```bash
docker compose up -d
```
Cela lance trois nÅ“uds Elasticsearch et Kibana dans des conteneurs sÃ©parÃ©s.

Une fois le cluster prÃªt :

- Kibana â†’ http://localhost:5601

- Elasticsearch â†’ http://127.0.0.1:9200

Se connecter Ã  Kibana avec :
```yaml
Nom dâ€™utilisateur : elastic
Mot de passe : changeme
```
#### 4. Indexer les articles :

##### A) Indexer l'intÃ©gralitÃ© des 21 742 articles du professeur
- Dans Objectif4_elastic.py, vÃ©rifier :
```python
INDEX_NAME = "tass_osint"
INPUT_FILE = "data/stage4_v3.json"
```
- Puis lancer 
```bash
python Objectif4_elastic.py
```

##### B) Indexer le dataset pour le dashboard "sentiment par pays"
- Lancer 
```bash
python convertir_pays.py
```
- Dans Objectif4_elastic.py, **modifier** :
```python
INDEX_NAME = "tass_osint_countries"
INPUT_FILE = "data/articles_pays_21k.json"
```
- Puis lancer 
```bash
python Objectif4_elastic.py
```
- Lâ€™index est alors crÃ©Ã© et alimentÃ©.

#### 5. CrÃ©er deux Data View dans Kibana :
Une fois les index crÃ©Ã©s dans Elasticsearch, il faut crÃ©er deux Data View distinctes dans Kibana afin dâ€™explorer sÃ©parÃ©ment :
- le corpus complet des articles (21 742),
- et le jeu de donnÃ©es agrÃ©gÃ© des sentiments par pays.

##### A) Data View 1 â€” Corpus complet
1. Ouvrir Kibana â†’ Stack Management â†’ Data Views â†’ Create data view.
2. Nom : `tass-osint`
3. Pattern : `tass_osint`
4. Time field : `date` *correspond Ã  un timestamp UNIX (epoch seconds)*
5. Valider la crÃ©ation.

**Champs principaux Ã  explorer :**
- `tags`
- `ner.PERSON`, `ner.ORG`, `ner.GPE`
- `structured.topics`, `structured.actors_mentioned`
- `structured.overall_sentiment`, `structured.sentiment_by_country.sentiment`

Cette Data View permet dâ€™analyser la structure sÃ©mantique complÃ¨te (entitÃ©s, thÃ¨mes, tonalitÃ©, acteurs, etc.) issue du pipeline dâ€™analyse OSINT.

##### B) Data View 2 â€” Sentiment par pays
1. Ouvrir Kibana â†’ Stack Management â†’ Data Views â†’ Create data view.
2. Nom : `tass-osint-countries`
3. Pattern : `tass_osint_countries`
4. Time field : `date` *correspond Ã  un timestamp UNIX (epoch seconds)*
5. Valider la crÃ©ation.

**Champs principaux Ã  explorer :**
- `country`
- `sentiment`

Cette Data View repose sur le fichier `articles_pays_21k.json`, gÃ©nÃ©rÃ© via le script `convertir_pays.py`.
Elle permet de visualiser le sentiment global par pays, par exemple :
- la moyenne du sentiment (`avg(sentiment)`) par `country`,
- lâ€™Ã©volution temporelle du ton des articles selon les zones gÃ©ographiques.

## 5. DÃ©pendances par partie
  
| Partie        | BibliothÃ¨ques principales                       |
| :------------ | :---------------------------------------------- |
| Objectif 1â€“2  | `requests`, `beautifulsoup4`, `pathlib`, `time` |
| Objectif 3    | `spacy`, `en_core_web_trf`                      |
| Objectif 3BIS | `python-dotenv`, `mistralai`                    |
| Objectif 4    | `elasticsearch`, `elasticsearch.helpers`        |

## 6. RÃ©sultats analytiques et visualisation

Une fois les donnÃ©es indexÃ©es dans Elasticsearch, nous avons conÃ§u plusieurs **dashboards Kibana** afin dâ€™explorer les tendances mÃ©diatiques et sÃ©mantiques de la presse russe (TASS).

### Objectifs analytiques
Lâ€™analyse vise Ã  identifier :
- Les **acteurs les plus citÃ©s** (personnalitÃ©s politiques, organisations, pays).  
- Les **thÃ©matiques dominantes** (topics) et leur Ã©volution temporelle.  
- Le **sentiment global** des articles, notamment **par pays mentionnÃ©**, pour Ã©valuer la tonalitÃ© du discours mÃ©diatique.  
- Les **corrÃ©lations entre acteurs et tonalitÃ©** (ex. relations positives/nÃ©gatives entre Ã‰tats).  

### Dashboards rÃ©alisÃ©s
1. **RÃ©partition des sentiments par pays**  
   â†’ Visualisation du champ `structured.sentiment_by_country.sentiment`, permettant de repÃ©rer les zones gÃ©opolitiques valorisÃ©es ou critiquÃ©es par la presse russe.

2. **FrÃ©quence des acteurs les plus citÃ©s**  
   â†’ BasÃ© sur `structured.actors_mentioned` et `ner.PERSON` / `ner.ORG`, pour dÃ©tecter les figures et institutions dominantes dans le discours.

3. **Analyse thÃ©matique (topics)**  
   â†’ Exploration des champs `structured.topics` pour observer les sujets rÃ©currents : conflits, diplomatie, Ã©nergie, Ã©conomie, etc.

4. **Distribution des sentiments globaux**  
   â†’ Moyenne des `structured.overall_sentiment` pour estimer la tonalitÃ© gÃ©nÃ©rale du corpus (positif / nÃ©gatif / neutre).

5. **Nuage de mots et filtres croisÃ©s**  
   â†’ Permet une exploration dynamique du corpus : filtrage par date, acteur, ou sujet afin dâ€™Ã©tudier les cooccurrences.

Ces visualisations offrent une **lecture OSINT claire** des orientations narratives de TASS.  
Elles permettent de **cartographier la rhÃ©torique mÃ©diatique russe**, en mettant en lumiÃ¨re :
- les **alliances perÃ§ues positivement**,  
- les **adversaires reprÃ©sentÃ©s nÃ©gativement**,  
- et les **thÃ¨mes gÃ©opolitiques dominants** sur la pÃ©riode Ã©tudiÃ©e.

>  Les dashboards prÃ©sentÃ©s (voir `Dashboard final.pdf` et `dashboard100.pdf`) illustrent concrÃ¨tement ces analyses.

## 7. RÃ©sumÃ©


### ğŸ”„ Pipeline global


TASS.com â†’ Extraction HTML â†’ NER (spaCy) â†’ Structuration (Mistral) â†’ Indexation (Elastic) â†’ Visualisation (Kibana)

Ce pipeline OSINT complet permet de :

1. Collecter des articles depuis TASS,
2. Extraire le texte et les mÃ©tadonnÃ©es,
3. Identifier les entitÃ©s nommÃ©es,
4. Enrichir les donnÃ©es sÃ©mantiquement via un LLM,
5. Visualiser les rÃ©sultats dans un dashboard interactif Kibana.

